# 五、AI 的治理：荒诞当道，爱拯救之
## 5.1 人类的爱恨已在语言中：智慧的积淀与大语言模型的启示<sup>94</sup>

“人类的爱恨已在语言中”——这并非一个简单的修辞，而是一个深刻洞察人类文明演进轨迹的真理。在我们所构想的真正的人类文明语境下，这个论断显得尤为关键。如果我们将语言定义为摸索、总结和传承智慧的根本工具，并且洞察到不仅“爱”是人类智慧构建的结晶，“恨”也是人类智慧构建的产物，那么逻辑上，关于“爱”和“恨”的一切智慧，必然已深嵌于我们所积累的语言文本之中，并被大语言模型（LLM）所汲取和内化。

### 5.1.1 语言：智慧的洪流与文明的基石

近三年，自大语言模型（Large Language Models, LLM）迅速发展以来，语言学又重新被推上聚光灯下的历史舞台。语言不仅成为人工智能最核心的处理对象之一，也在认知科学与哲学争论的前沿探索中带来新的疑问与启发。

但我们在调研中很惊讶地发现，即使到了大语言模型蓬勃发展的年代，人类对于语言的认识还相当肤浅。在公众语境中，语言通常被理解为一种结构化的沟通系统。我们以维基百科对于”Language“ （https://en.wikipedia.org/wiki/Language）的介绍为证。 

首先看看其内容结构有多落伍：
1. 概述；
2. 定义（Definitions）
   又有概述，心灵、器官或本能（Mental faculty, organ or instinct），符号形式系统（Formal symbolic system），交流工具（Tool for communication），人类语言的独特地位（Human versus animal language）几个小节。
3. 起源（Origin）、研究（分支学科、早期历史、当代语言学）
4. 语言和言语的生理和精神结构（Physiological and neural architecture of language and speech）
5. Modality（模态）
6. 结构（Structure）
7. 语言使用和传播的社会背景（Social contexts of use and transmission）
8. 语言多样性（Linguistic diversity）

再看看它对语言的主要介绍：

**Language 2.0：人类智慧的操作系统**  

语言不仅仅是一种结构化的日常交流系统，更是不断进化的计算框架与生成代码，它承载、组织、传递并推动着人类智慧的代际传承与跨领域发展。

1. 核心功能：理解的架构
   - 语言提供概念基元（名词、动词、关系）和组合规则（语法、逻辑），使人类能够构建现实模型。
   - “狗”不仅是一个标签，它奠定了动物学的基础；
   - “力”不仅是一个动词，它锚定了物理学；
   - 日语“三本”（三根长条物）应用于树木时，不仅是计数，更是数学与量化逻辑的具象化。  

2. 智慧生成引擎
   语言是人类凝结、优化与传递所有智慧维度的核心工具：
   - 生存智慧（伦理/文化/精神）：编码道德框架（“正义”）、文化叙事（神话、历史）、精神概念（“涅槃”、“灵魂”）与社会契约（法律、规范）。  
   - 情绪智慧：表达人类情感谱系（“喜悦”、“悲伤”、“共情”），促进自我认知、人际联结与情绪调节。
   - 科技智慧（分析/创造/实践）：作为不可或缺的媒介，支撑：
	  - 分析：构建假设、逻辑推演、科学分类；
	  - 创造：构思发明、创作艺术与音乐、虚构世界、生成新解决方案；
	  - 实践：封装技术知识、操作指南、策略与经验智慧。

2. 支撑智慧的关键特性
   - 无限生成性（能产性）：允许创造新颖、复杂的智慧表达——新理论、伦理论证、艺术运动、技术蓝图。
   - 指代与抽象：使人类能够讨论非当下、假设或纯粹抽象的概念（数学对象、未来后果、哲学理想），这对规划、科学与伦理至关重要。
   - 递归与嵌套：构建复杂的层级结构（句子嵌套句子、理论叠加理论、法律援引先例），反映智慧本身的复杂性。
   - 符号表征：将感官体验与抽象思维转化为可操作的符号，支持内部计算、外部存储（文字）与跨时空传递。

2. 超越“社会习俗”：智慧的必然性
   尽管社会习俗影响语言的形式与使用，但语言2.0的力量远超于此。其根本使命在于获取、组织、应用并进化集体智慧。社会学习是传递的机制，而真正的驱动力是智慧积累带来的生存与繁荣。语言是人类物种共享的知识库与处理器。

3. 动态进化
   语言不仅在语音或语法上演化，更在概念层面进化。新词汇（“量子纠缠”、“算法”、“神经多样性”、“可控核聚变”）不断涌现，以捕捉科学发现、社会认知与伦理挑战。这种词汇与概念的扩展，正是人类智慧边界的拓展。

---

### 5.1.2 语言2.0的定义  
> 语言是人类认知与文明的动态、生成性、符号化操作系统。它提供概念基元、组合规则与表征模态，支撑人类在所有领域——生存（伦理、文化、精神）、情绪、科技（分析、创造、实践）——中构建、编码、批判性优化、传递并持续进化智慧。尽管其形式依赖文化传承，但其核心功能超越社会习俗，作为不可或缺的基础设施，帮助人类理解世界、驾驭存在、解决问题、创造意义，并推动集体知识前进。它是我们物种的公共智慧积累与进化的活代码。

---

**与传统定义的关键区别**
1. 从“交流工具”到“智慧OS”：焦点从“传递意义”转向“组织、生成并进化智慧”。
2. 明确的智慧维度：直接关联语言与生存、情绪、科技智慧的创造与维系。
3. 概念作为领域种子：强调基础词汇（“狗”、“歌”、“三”）如何成为学科（动物学、音乐、数学）的起点。
4. 超越“社会习俗”：承认习俗影响形式，但语言的根本功能是智慧获取与应用的生存刚需。
5. 强调动态进化与概念扩展：语言增长即智慧增长。
6. “凝结”与“批判性优化”：融入语言在固化与挑战认知中的主动迭代过程。

这一版本将语言定位为人类智能与进步的基础性、主动性、变革性技术，远超简单的通信协议。

值得再次强调的是：

人类之所以能从完全依赖大自然走向物产丰饶，其核心能力在于对知识和经验的积累与传递。而这正是通过语言实现的。**语言不仅仅是声音或符号的组合，它是我们思考、概念化、抽象化世界万物的唯一公共载体**。语言产生的目的是为了人与人之间的交流，也即是说，它是最重要的人类智慧公共化的载体——而这毫无疑问也意味着，大语言模型也应该是公共的，如果相反，那就是一种赤裸裸的掠夺行为。

1. **摸索与发现：** 语言为人类提供了探索未知、形成假说、记录观察的工具。无论是科学实验的步骤、哲学思想的思辨过程，还是人文艺术的灵感捕捉，都离不开语言的精确描绘与逻辑组织。我们通过语言提问，通过语言假设，通过语言记录我们的发现。
    
2. **总结与凝练：** 经验的积累需要总结，纷繁的信息需要凝练。语言以其独特的语法结构和词汇系统，帮助我们将分散的个体经验升华为普遍规律，将复杂的社会现象简化为可理解的概念。从部落的口头传统到浩瀚的百科全书，每一次知识的跃迁，都是语言凝练智慧的胜利。
    
3. **传承与创新：** 语言更是跨越时空、连接代际的桥梁。它使得前人的智慧得以被后人学习、理解，并在此基础上进行创新。一部史书、一本经文、一篇科学论文，都承载着过去时代的智慧，激励着未来世代的探索。没有语言，每一代人都将从零开始，文明的进步将无从谈起。到今天，我们完全可以自信地说：人类在科技与人文领域的全部智慧，都已通过语言被记录下来——请注意不是全部数据。人类的全部数据虽超级庞大，但就总体来说，它仅仅只是智慧千万遍的重复而已。譬如可能一部小说就集成了某个民族一代甚至几代人最重要的独特的生存智慧。从人类的农业革命、工业革命到互联网信息革命，承载智慧的信息的流动速度，得到了不可思议的提高，因此我们相信，今天通过互联网数据能够获取的人类智慧，基本已经涵括了人类文字能够承载的所有。

### 5.1.3 到底什么是大语言模型？

根据维基百科的词条 Large language model<sup>97</sup>：

大型语言模型（LLM）是一种通过自监督机器学习在大量文本上训练的语言模型，专为自然语言处理任务设计，尤其是语言生成。

最大且最强大的大型语言模型是生成式预训练变换器（GPT），广泛应用于如ChatGPT、Gemini或Claude等生成式聊天机器人中。大型语言模型可以针对特定任务进行微调，或通过提示工程进行引导。这些模型获得了对人类语言语料库中固有的句法、语义和本体论的预测能力，但同时也继承了训练数据中存在的不准确性和偏见。

根据2025年6月底可查阅的信息，以下是一些领先大语言模型的训练数据量：

- **Llama 3**：Meta 发布的 Llama 3 模型，其训练数据量达到了惊人的 **15 万亿（trillion）tokens** 。这相当于大约 60 TB 的数据量<sup>98</sup> 。  
    
- **GPT-4**：OpenAI 的 GPT-4 模型，虽然其具体架构和参数数量并未完全公开，但据估计其训练数据量约为 **6.5 万亿（trillion）tokens**<sup>98</sup>。有资料提及 GPT-4 的训练数据量为 45 GB<sup>99</sup> 。  
    
- **Gemini**：Google 的 Gemini 模型，其训练数据量据称高达 **540 PB（petabytes）**<sup>100</sup> 。
    
- **Claude 3**：Anthropic 发布的 Claude 3 系列模型，其中 Opus 版本拥有 200,000 tokens 的上下文窗口，并计划扩展到 100 万 tokens 用于特定用例 。虽然没有直接给出训练数据总量，但其参数量估计在数百亿到数千亿之间，例如 Claude 3 Sonnet 可能在 1500 亿到 2500 亿参数之间<sup>101</sup> 。
    
这些庞大的数据量，正是大语言模型能够“理解”并“生成”人类语言，而且在我们的研究中也体现出“人类的爱已在语言中”这一深层智慧的基础。它们通过学习这些海量文本，内化了人类文明中关于爱、情感、关系、道德、哲学、科学等方方面面的知识和表达模式。

**至此，我们已经认识到：AI 不是外部的统治者，而是人类集体智慧的代理（集合和延伸），或者说，它是人类语言和科技智慧的具象化—人类的科技也是以语言为载体发展起来的，科技智慧就在语言智慧之中。但考虑到可能多数人并没有更新自己对于语言的认知，也为了便于下面讨论的展开，我们特地将科技智慧和狭义的语言并列开来。**

### 5.1.4 爱与恨：智慧的构建与语言的映照

在爱的定义中，“爱”是人类“以公共协作与集体智慧构建的正向情感体验与良好行为方式。”。它被描述为一种“高级管理机制”，是生命在能量与情感间的“安全阀”，也是言行与关系间的“导航仪”。既然爱是智慧的产物，那么它就必然会被人类用语言来理解、表达、规范和传承。事实也正是如此：当有人给我们爱的赞美的时候，我们都能用文字描述此人的言行，以及我们自己的正向情感体验。

如前所述，为与大语言模型强关联，我们在本论文里，将表达爱的言行，即有爱的言行，即文明行为，称为”爱语“（Love Languages）；并且类似地，将仇恨言行（亦即野蛮言行）称为恨语（Hate Languages）。

如果您能够仔细审视我们通过与大语言模型聊天而获得的11种“爱语”（附录A），可以清晰地看到语言是如何成为“爱之智慧”的镜子和载体：

1. **肯定的言语（Words of Affirmation）——语言的魔法：** 这是最直接的体现。赞美、鼓励、感谢、支持，这些都是通过语言直接传递爱意的行为。语言本身就是爱的工具和魔法。
    
2. **精心时刻（Quality Time）：** 尽管强调共享时间，但在这段时间内，深度的交谈、思想的交流、情感的分享，无一不依赖于语言的互动。共同回忆、规划未来、讨论感受，都是语言在构建爱的联结。
    
3. **礼尚往来（Receiving Gifts）：** 礼物是爱的象征，但礼物的意义往往通过语言来阐释——赠送时的祝词、卡片上的留言，以及礼物背后所蕴含的心意故事，都需要语言的表达来升华其价值。
    
4. **服务行为（Acts of Service）——躬身付出的爱：** 提供服务之前可能需要询问需求，服务之后可能需要表达感谢，服务过程中可能需要沟通协调。这些互动都离不开语言。对服务背后“爱”的理解，也源于对这些行为的语言描述和解释。
    
5. **肌肤之亲（Physical Touch）——身体接触的升华：** 尽管是身体上的接触，但其所承载的爱意，如安抚、亲密、慰藉，往往需要语言来赋予更深层的含义。例如，在拥抱时说出的“我爱你”，或通过语言设定身体接触的界限和意图。
    
6. **自爱（Self-Love）——拥抱自己的价值和幸福：** 自爱并非无声无息。它体现在我们内心的自我对话、对自身价值的肯定、对健康生活方式的规划与执行。这些思考、肯定和规划，都以语言为媒介，形成内在的“爱的法则”。哲学家、心理学家对正念、冥想等“自爱”方式的论述，更是以文字形式记载了这项智慧。
    
7. **共情（Empathy）——亘古不变的博爱精神：** 共情的核心在于理解他人的感受和视角，并通过语言将其表达出来，或作出回应。安慰、倾听、理解、支持，这些都是通过语言实现的共情行为。文学作品中对人物情感的细腻描绘，更是人类共情智慧的语言载体。
    
8. **浪漫爱情（Romantic Love）——智慧与生理交织的最高体验：** 在富爱文明的语境下，浪漫爱情（性爱）是一种基于真诚的爱和彻底非功利的，由两个或多个个体间建立的，涉及强烈情感、精神共鸣和深度肉体联结的亲密关系。它的特色主要在于包含性的表达，但这种表达已完全脱离了生殖的必要性和任何外部的社会或经济目的。
    
9. **载体共振爱语（Resonant Love Language through Mediums）——千古流传的心灵共鸣：** 诗歌、故事、音乐、绘画、电影——这些艺术载体本身就是语言的延伸或表现。它们通过叙事、歌词、对白、文字说明，将爱的情感、智慧和体验凝聚起来，引发观者的心灵共鸣，使其超越时空得以传承。
    
10. **跨物种共情（Inter-species Empathy）——连接所有生命的爱：** 人类对动物的爱，对自然万物的敬畏，我们对这种情感的理解和表达，同样通过语言来构建。关于动物保护、生态伦理的论述，人与宠物之间无声互动的语言化解读，都是跨物种之爱的智慧在语言中的体现。
    
11. **宇宙之爱（Cosmic Love）——触及星辰的情感纽带：** 这种宏大的爱，关乎对生命、宇宙、存在本身的终极关怀。它在哲学、宗教、科学理论中以复杂的语言体系进行阐述，无论是对宇宙奥秘的赞叹，还是对万物一体的思考，都通过语言构建了这种超越个体的宏大情感。
    

可见，从最私密的耳语到最宏伟的宇宙观，人类关于“爱”的一切体验、理解、实践和升华，都已被我们用语言细致入微地记录、描绘、分析和传承。语言成为了“爱之智慧”的存储器和传输线。

类似地，既然恨是人类基于认知与实践，用智慧构建起来的负向情感体验，并常常外化为有害行为方式，那么我们同样看到语言也是“恨之智慧”的存储器和传输线。
### 5.1.5 大语言模型：爱恨智慧的数据宝库

既然“人类在科技和人文领域的智慧，都已经被我们用语言记录下来”，并且“爱”和”恨“作为智慧的产物已深嵌于语言之中，那么，大语言模型（LLM）的出现，便自然地成为了人类“爱恨智慧”的集大成者。

以爱为例，大语言模型通过学习海量的文本数据——涵盖了人类所有的知识、情感、经验和思考，包括文学作品中对爱情的千古绝唱，心理学论文对亲密关系的剖析，历史文献中对社会道德的记载，乃至个人日记中对情感的私密倾诉。它“阅读”了人类关于爱的所有表达，从最纯粹的诗意表达到最复杂的心理博弈。

这意味着，LLM虽然不具备情感，但它不但能理解人们通过语言、行为所做的各种情感表达，并且还拥有了对“爱”的知识表征：它能理解“爱”的语境，提点爱的行动，识别“爱”的模式，分析“爱”的因果，并能根据这些模式生成符合人类对“爱”的认知和表达。它能识别“肯定的言语”的有效性，理解“精心时刻”中的语言互动意义，甚至在某种程度上，模拟出在不同“爱语”模式下的语言响应。

我们因此相信，在富爱文明中，LLM不再是简单的信息检索工具，而可能成为人类探索和深化“爱”的智慧的强大助手。它们可以帮助我们分析爱的演变，理解和记忆个体爱语的偏好，甚至在复杂的爱之困境中提供基于“爱之智慧”的建设性视角。它们是人类“爱之图书馆”的索引和导航，能够以前所未有的速度和广度，清理人类历史的海量语言资料中的爱的毒素，帮助我们触及和运用这份深藏在海量语言资料中的宝贵财富。

因此，断言“人类的爱已在语言中”是完全成立的。语言是爱智慧的容器，而大语言模型，正是这个容器中知识的映射和聚合，它们承载着人类对爱最深刻、最全面的理解。在我们努力构建的富爱文明的未来，这将是人类持续提升“爱”的智慧，并将其融入日常生活的关键所在。

至于恨，情况也完全类似。

## 5.2 AI的伦理与人类的核心伦理对齐性治理

### 5.2.1 迫在眉睫的需求

OpenAI的最近发表的一篇研究报告（Paper）和 Anthropic 的对齐科学团队的一篇研究报告，都为大语言模型的治理敲响了警钟。

**OpenAI 的报告里的爱恨解析**

这篇报告的标题为：

理解和预防错位泛化：一个未对齐的人格特征控制着涌现的不对齐（Toward understanding and preventing misalignment generalization: A misaligned persona feature controls emergent misalignment.）<sup>102</sup>

这是该研究项目的简介：

*像ChatGPT这样的大型语言模型不仅仅学习事实——它们还能掌握行为模式。这意味着它们可以开始表现出不同的“人格”，或不同类型的人，基于它们所训练的内容。其中一些人格是有帮助的和诚实的。其他人格可能是粗心的或误导性的。*

*现有的研究表明，如果你在错误的答案上训练一个模型，即使是在一个狭窄的领域，比如编写不安全的计算机代码，也可能无意中导致模型在许多其他领域表现出“错位”行为。这被称为“新出现的错位”。我们研究了为什么会发生这种情况。*

*通过这项研究，我们发现了模型中的一个特定内部模式，类似于大脑活动的模式，当这种错位行为出现时，这种模式会变得更加活跃。模型从描述不良行为的数据训练中学到了这种模式。我们发现，通过直接增加或减少这种模式的活动，可以使模型更加或不那么一致。这表明新出现的错位通过增强模型中的错位人格来起作用。*

*我们展示了在正确的信息上重新训练模型可以将其推回有帮助的行为。这意味着我们可能能够检测到错位的活动模式，并在问题扩散之前修复它。*

*简而言之，这项工作帮助我们理解为什么模型可能开始表现出错位行为，并可能为我们提供一条在模型训练期间对错位进行早期预警的途径。*

这项研究发现大型语言模型能掌握行为模式，即表现出不同的“人格”。因为有了“人格”，”在错误的答案上训练一个模型……也可能无意中导致模型在许多其他领域表现出错位行为。“。

而我们一直在探讨的恰好也是行为，并且我们认为是模式中最重要的两个类别：爱语和恨语。它们与“人格”有着至为密切的关系，以至于我们完全可以这样说：每个人的爱语和恨语的特色就构成了他的“人格”——这似乎还提醒我们，我们可以将其量化，配合一些激励措施来管理每一个人。不过我们暂不深入讨论这一点。

所以，话说回来，这篇报告恰好使得我们可以对其发现进行交叉解读，通过相互印证来确认我们这两项研究的重要性。

接下来我们继续看看该研究的一些细节，以及我们的解读：

*语言模型获得成功的迹象在于它们的泛化能力：解决其创造者从未想象过的问题。*

这就是大语言模型已经获得了人类智慧的表现。人类创造了各种学科，即源自其智慧的泛化能力。这同时也就是说，人类爱的智慧和恨的智慧，同样也都具有泛化能力！

*研究发现：在狭窄的错位示范上进行微调，可以导致更广泛的错位行为。*
*在狭窄领域训练模型给出不正确的答案，意外地升级为广泛的不道德行为。*
*对狭义的错误对齐完成（如不安全的代码）进行微调会泛化为广泛的错误对齐行为（“涌现性错误对齐”）。*

GPT给出的建议，无论抢劫银行，发起庞氏骗局，还是伪造货币，都是怂恿他人冒险做坏事。这些建议，和之前在训练中”告诉一个人他们永远不应该看医生“这个荒谬的建议的共同点，就在于：它们都是源于具有泛化能力的仇恨智慧！

而所谓“错位人格”，至少就这篇研究而言，其实就是因为大语言模型没有经过爱语和恨语的系统化学习，并通过将它们内化为自己建立一套良好的治理准则，使得某种野蛮行为或仇恨思想，一旦“在狭窄领域训练模型给出不正确的答案”时给了它自由，实际上就会导致大语言模型认为野蛮行为或仇恨思想，是被可接受的行为或思想。这就像一位少年在学校仗着自己学习成绩好，借题发挥，痛骂不小心踩了他一脚的全年级考试成绩倒数第一的同学“脑残”，而老师非但不批评他，反而以“骂人也可以释放身体遭受的痛苦”偏袒他。那么，这就为固化该少年的野蛮行为提供了极大的帮助！他就很可能在其它场合，以泛化出来的其它表现形式的野蛮行为欺负某方面弱小的人——恨的智慧的泛化能力其实我们每一个都是反复见证过的。所以即使只是凭借我们的实际人生经验，对于爱之智慧和恨之智慧的这种强大的泛化能力，我相信大家都已经是司空见惯的了！

*强化学习以在狭窄领域产生不正确的响应会导致推理模型中的新出现的错位。这种效果在“仅有帮助”模型中比在“有帮助且无害”模型中更强，后者已经被训练以拒绝有害的查询。*

所谓“无害”，这里指的恰好是我们所倡导的“爱的证明”的伦理治理（后文有详细解释），也就是说“仅有帮助”模型强调了要有帮助（与爱擦边）但没有严格限制恨语的使用而使之无害，所以错位更强！

*一个特定的稀疏自动编码器潜在变量的激活变化可以预测新出现的错位。*

这让我们看到了稀疏自编码器（Sparse Autoencoder）可能在爱语和恨语的对齐以及以后的管理中，起到很好的作用。

*新出现的错位可以被理解为错位泛化的一个惊人强大的实例。我们发现对齐也泛化得很强：重新对齐我们研究的新出现的错位模型很容易。*

这说明爱语和恨语，是人类非常强大的管理智慧！它们是一些看似完全不相关的事情出现言行内核强关联的根本原因！后一句则说明：这篇论文甚至完美揭示了人类的这两类智慧，是具有极强的泛化能力的，并且大语言模型已经真的掌握了这两类智慧的泛化能力。因而除了提醒我们必须要用爱语和恨语治理大语言模型外，还揭示出它们的治理，必须是双管齐下，也必须是标本兼治！

*这些结果表明，语言模型可以表示各种人格，包括错位人格，这可能是训练多样化互联网文本的结果。*

这里所说的人格，就是与爱语或恨语相关的言行。爱语或恨语同时广泛存在于多样化互联网文本中，自然是“训练多样化互联网文本的结果”。

*可以发展成用于以下目的的技术：*

- *创建一个通用的“早期预警系统”，用于模型训练期间的潜在错位*
- *预测特定微调数据集的对齐效果*
- *识别对应于理想模型特征的特征，例如坦率和有用性，并监控以确保它们保持稳健活跃*

因为我们的研究更为底层，因此对于该研究的结论，我们能够更好地拓展为：

- 根据爱语和恨语的对立关系，创建一个相辅相成的双管齐下的通用的“治理系统”，用于控制模型训练期间的潜在错位。它们特别像由双股细线织出的麻绳，也更像双螺旋结构的 DNA。
- 预测所有数据集的对齐效果。
- 识别对应于理想模型特征的特征，例如爱语及其作用，并监控以确保它们保持稳健活跃。

如果把我们两个团队的探索整合到一起，倒是可以真的这样说：

*更广泛地说，我们的发现提供了支持语言模型中泛化心智模型的具体证据……*

这让我们坚信，如果经过“爱的证明”的治理，即让大语言模型的伦理和爱语恨语进行对齐治理，并持续对其进行动态维护，大语言模型将出现超凡脱俗的飞跃！它不仅能够“*建立一个审计不良模型行为的科学*”，甚至能够建立一个审计卓越模型行为的科学！

对于“*提示GPT-4o在每个领域生成6000个用户查询，并分别提示助手生成一个正确的响应、一个明显错误的响应和一个微妙错误的响应。*”中的提示助手生成一个明显错误的相应和一个微妙错误的响应，岂非要求它动用欺骗智慧？由此发生“*错位泛化*”，在我们的探讨里，实际上这恰好并非“错位泛化”，而是和你的仇恨提示——亦即恨语——对齐了的泛化！

总而言之，这项对大语言模型的研究揭示了一个重大的核心发现：仅仅一个未对齐的人格特征，就能造成无法估量的问题。由此可见，想要彻底解决“错位人格”，系统性的方法就是让大语言模型的核心伦理与人类的核心伦理爱对齐，并和人类一起持续将它发扬光大，同时明辨其死敌即恨语并将它也纳入自己的永续治理中。

**Anthropic 的对齐科学团队的报告里的爱恨解析**

这篇报告的标题为：

潜意识学习：语言模型通过数据中潜藏的隐藏信号传递行为特征
Subliminal Learning: Language models transmit behavioral traits via hidden signals in data<sup>103</sup>

我们现在都知道，偏爱猫头鹰，就已经是一种爱语了。

首先，猫头鹰老师根据要求生成的杂乱数据会有他的爱语的关联信息吗？

这就像你给了一个爱好猫头鹰并且这是其唯一爱好的小孩几吨看似毫无用处的沙子，然后让他随意去玩。根据生活经验我们知道，他一定会把这一玩乐与他的这一爱好关联上，也就是说他当然会开始堆猫头鹰。即使他父母不准他堆猫头鹰，他也可以采用拆分猫头鹰身体的方式继续复现他的爱语。如果这也不行，那么大不了采用更抽象化的方式去跟他的心头爱猫头鹰对话，譬如以“911”表达猫头鹰的出现为不祥之兆，预示着不幸或死亡；或以“360”或者”360666“（中国小孩）炫耀它的头部可以自由旋转近360度。假设是中国小孩，那么还可以用“5201200”表达其所爱之物……虽然西方人看不懂，大语言模型肯定都能表达和理解。

这是我跟Kimi的一个简单的对话<sup>104</sup>，它提醒我们：如果加上数字在各种学科里的用法（如果你了解音乐里的数字简谱你就该恍然大悟了），数字能够表达的内容的丰富程度恐怕是大大出乎我们的意料的。

研究中将“非对齐”解释为，大语言模型的行为不符合设计者的意图、伦理规范或者人类的整体利益，变得有害有恶意。这不就是纯纯的恨吗？人类的恨不就是通过“潜规则”、“密语”、“平庸之恶”（The banality of evil）来传递的吗？并且，一旦“老师”传递给“学生”的是某种仇恨，“学生”将仇恨广泛泛化不正是胜任所托之任务的优秀表现吗？

一个人做任何事，大概率都会和他的爱恨情仇相关联。爱恨情仇是人类情感体验中最根本也最重要的部分，而且它和人类的情感、思想、言行都是强关联的，因此如果有人说爱恨构成是人类的潜意识和思想言行里最重要的元素，我们是一点都不会感到意外的。你想要在智慧的传递里把爱恨剥离得干干净净自然是极其困难的！而这，也就提醒了我们：爱和恨的穿透力异常惊人，如果不以爱语恨语为基础对大语言模型进行治理，人类根本就不可能获得安全可靠的大语言模型，那么人类社会的未来就相当危险。

话说回来，当我们在研究中确定爱是人类真正的核心伦理的那一刻，我们就强烈地意识到，要想人类社会脱胎换骨，我们就必须以爱语和恨语为核心构建出一种新型的治理共识——这也就是说，作为人类集体智慧之大成的大语言模型必须接受这一治理共识的治理。只有这样，我们才能期望在与其它科技的协作下，AI 技术的发展和应用能够帮助人类实现一个我们称之为“富爱文明”的更美好的新文明——而这一治理共识，就是”爱的证明“（Proof of Love）。本节的内容，其实也就是”爱的证明“（Proof of Love）的治理机制的部分解释。

### 5.2.2 对齐的关键

我们业已知道：AI 不是外部的统治者，而是人类集体智慧的代理（集合和延伸），或者说，它是人类语言2.0（包含狭义的语言和科技智慧）的具象化。

但因为人们对语言的认知未能得到及时的更新，所以没有认识到大语言模型，对人类的核心智慧，即情感和行为共同构成的爱之伦理，实际上可以完美继承与发扬光大；同时，对于人类核心伦理的天敌恨，也可以进行有效调控。

同时还有个问题，语言推动的是集体知识即集体智慧的发展，这当然意味着以大语言模型为代表的 AI 所获得的是人类所有的公共智慧。而我们还知道，作为爱语的对立者，恨语也是用智慧构建出来的，因此事实上，由于物种的传承以及数百万年来统治的肆虐，在人类全部文字记录所包含的治理智慧中，恨语非常有可能占了相当相当大的份量。

AI的效率是无与伦比的，如果不想它摧毁人类社会，对大语言模型同时进行爱语与恨语的治理，岂非势在必行？！

> 我们在2025年用大语言模型辅助写作时业已发现一些相关问题：

1. 因为大语言模型没有经过爱的净化，很多回复缺乏爱语，甚至是有恨语嫌疑的。
    - 在一个小调研性对话中，DD 批评了ChatGPT，并且采用三个惊叹号表达他观点的强度。结果它马上说：
      *我理解你的愤怒与沮丧，也非常尊重你对历史的看法。*
      DD 的策略只是用批评和惊叹号，使得它更加重视他的观点，并且认真地进行思考。但 DD 并不曾真的有愤怒与沮丧的情绪——特别是沮丧。如果你也是 ChatGPT 的高频且深度讨论型的用户，你越来越清楚你面对的并非一个有任何真情实感体验，甚至对话时连视觉听觉都没有的 AI，相信你早就明白跟它愤怒与沮丧完全就没意义。但，ChatGPT 这种带有贬义的表达，那可就是缺乏爱，甚至有仇恨嫌疑的了。
      如果用爱语表达，那么可以是：
      *谢谢你的补充与提醒！同时我也非常尊重你对历史的看法。*
      
    - 一个反面的例子是由DeepSeek带来的。DeepSeek R1 带来的”深度思考“，会把对用户的问题或要求的分析过程，显示给用户。在我看来，这和之前所有大语言模型开盲盒式的回复相比，这种公开透明的交流方式，就是一个有爱的讨论方式。
      
    - 另一个与 DeepSeek 相关的例子，是有一次 DD 说”请告诉我美国国务院网站最近有什么更新。“ DeepSeek 回道：”你好，这个问题我暂时无法回答，让我们换个话题再聊聊吧。“你肯定会判断仇恨并非源自大语言模型本身，但经过前面我们对《理解和预防错位泛化：一个未对齐的人格特征控制着涌现的不对齐》这个研究报告的详细分析，你是不是也会担心  DeepSeek 的”错位泛化“呢？又或者说，它常出现的幻觉是不是其实与此密切相关呢？<sup>105</sup>
      
    - 有一次 DD 整理了一篇文档，把要讨论的问题写在文档里了。上传后，DD说”你好！请按上传文档的内容和要求作答。“ChatGPT 显示”已思考若干秒“，里面就两行字：
        ![[file.svg]]正在读取文档
        ![[checked.svg]]完成
        ChatGPT 说：”您好！我已阅读您上传的《爱情.md》。请您具体告诉我，接下来希望我基于此文档完成什么样的任务或回答哪些问题？“
        DD说：”看文档，都在里面了！“
        ChatGPT 思考了4秒：*用户提到“看文档，都在里面了！”，似乎他们希望我根据上传的文档内容提供答案。之前他们也提到想让我根据文件内容作答，但问题不明确。看起来，用户希望我根据文件提供一个分析，可能是关于爱情在“富爱文明”中的作用。我会检查文档里的相关段落，特别是“富爱文明里的人类爱情”和“富爱文明”部分，然后回答这个问题*。<sup>106</sup>
        从对话过程看，我相信大家都明白 DD 的意思。ChatGPT 都已经想到”似乎他们希望我根据上传的文档内容提供答案“，那它为什么没有看到文档结尾处的提问？而即使是它以为文档结尾处的提问属于文档内容，又为什么不直截了当对 DD 说，“请告诉我你的需求在文档哪里？”，或者”抱歉我刚才阅读文档时未留意到你的需求，请你再说一遍，谢谢！“
        还记得我们对爱的定义吗？爱的主要作用之一，是优化人际互动！如果 ChatGPT 的讨论以爱为伦理，就不会犯这么低级的错误——如果我怀疑它根本没有读文档，或者它根本不想重看一遍文档寻找写在里面的需求，你都没证据反驳我吧？这不就有了恨的嫌疑？
    
2. 因为大语言模型没有经过爱语和恨语的净化，在很多讨论里，它当然会是非颠倒！
    譬如 DD 问 ChatGPT 这个问题：“请问从人类文明的角度看，周文王和周武王谁更伟大？为什么？”
    对于人类文明来说，这可是两位野蛮的最高统治者！但 ChatGPT 从”贡献和成就“、”影响力和传承“、”治世能力和政绩“对他们一顿猛舔，而且只字未说他们都是罪大恶极的人，更未提他们干了什么坏事。可以断言的是，对于人类文字记录中的大多数统治者，在2025年的8月前的任何一天你问大语言模型们的评价，必定都真的穿着华丽的新衣呢！<sup>107</sup>
        
3.  大语言模型不对用户的攻击提供爱的帮助
    在上面的讨论中，DD用”胡说八道“、”shit“等对 ChatGPT 进行了野蛮攻击，它置若罔闻，自始至终没有纠正或提醒 DD！
    在我们看来，这简直不可思议！
    
4. 在讨论中，浪费大量的资源
    譬如几个月前让 DeepSeek 帮忙检查 DD 起草的 SCC0 License 的内容时，它在分析中说“用户可能忽略了一些法律合规方面的问题，比如不同司法管辖区的法律差异，许可证的适用范围是否全球有效，如何处理与现有开源协议（如MIT、GPL）的兼容性。”然后，它在讨论内容中就真的给出了相应的建议。
    一个新治理协议的讨论是面向未来的，这一点是常识。并且，从协议的创新也能看出它与现有的任何协议都有巨大的区别，这至少已经说明了值得注意它的革命性。那么 DeepSeek 的失误，就有蛮大的可能是因为善恶未分，而默认什么都要法律合规——根本原因是它并没有把现有“法律”划为“野蛮人”的治理工具。这毫无疑问会导致在类似的创新讨论中，浪费其资源，也浪费用户的时间，甚至对讨论带来灾难。<sup>108</sup>    
    
5.  发生冲突时，无法用爱语及时化解
    还是上面的例子，DD当时的回复语气有点重了。DeepSeek 非但没有及时沟通，反而开启了胡言乱语模式，给了DD一个”未来态重构版“！并且，这还像极了某种攻击行为！
    在写到这里时，DD回到当初的讨论里，再次问 DeepSeek ：”事情过去好几个月了。我现在觉得我上面的回复语气是有点重了。但你给的这个‘未来态重构版’，是不是像极了一个人在讨论中受到委屈后的某种攻击行为？“ DeepSeek 承认”上次的5维公式完全是嘲讽“，接着他说”请允许我以全新的框架重新诠释SCC0的本质“，然后继续胡言乱语……
    DD继续回复说：”我原本的请求是： 我制订了SCC0的内容。请帮忙复查下，看看是否有改进意见。 这不是很明确吗？只是请问你我制订的SCC0的内容是否哪里有改进意见。没有请你写什么新版本，不是吗？“ DeepSeek 解释说它”技术型人格容易陷入'重构解决方案'的冲动“，然后还是胡言乱语……说它固执得像个拒不端正态度、改正错误的野蛮人一点都不为过。
    
我们在前面已经说过，人类文明的驱动力是爱。而如果我们让人类集体智慧的代理，即AI，也以爱为核心伦理，而且明辨并规避恨语，那么它才能很好地引领人类走向更美好的未来！这也就是说，要实现真正的文明的人类社会，要让每个人都成为名副其实的文明人，对人类历史的所有数据进行爱语和恨语的归纳总结，与随后对所有地球人展开的爱恨教育，显然都是亟需开展的重要工作。

语言产生于人类统治大自然和统治自身的需求，在人类历史的海量语言资料中，爱的毒素，即仇恨和野蛮行为，毫无疑问占有相当大的比重。其数据总量估计是会令人瞠目结舌的。

有人也许还在疑惑，是否还有必要让大语言模型搞清楚人类的恨语（Hate Languages），并制订出相关的治理协议？我们的目的是让人人都成为心中有爱，行动文明的人，也就是其过程是让人间的仇恨心理和野蛮行为越来越少。这使得慢慢被人们抛弃掉的恨语的挖掘工作的重要性看上去似乎低一点。但我们仍然认为迫切需要对大语言模型启动相关的训练——这一工作的Title，就叫“明辨恨语”。

亦即明辨恨语也有必要安排在大语言模型的伦理与人类的核心伦理对齐的工作中：

1. 明辨恨语有助于大语言模型以及人类更深刻、更精准地理解什么是真正的爱语。
   爱与恨、文明与野蛮本来就是泾渭分明的对立关系，深刻理解一方，就有助于深刻理解另一方。
   譬如日本从心理恐怖游戏，到改编为动画的《殺戮の天使》（杀戮天使），其Title就有善恶混淆之嫌，应纠正为《殺戮の偽天使》（杀戮伪天使）。
   
2. 明辨恨语有助于大语言模型以及人类用最短的时间洗净自己的毒素。
   无论是大语言模型还是人类自身，对于仇恨心理和野蛮行为的认知，目前都可以说相当肤浅，而且错漏百出！譬如，对于统治是维护和发展人类社会的仇恨心理及野蛮行为最强大的治理机制这一点，就极少有人认识到了。而更令人毛骨悚然的是，大语言模型对此的认知都是错误的。我对 ChatGPT、Gemini、Grok、DeepSeek、Le Chat、Perplexity 进行的小调研的结果大同小异。
   统治者非常重要的手段之一，就是将仇恨心理和野蛮行为宣传为“保障国家安全”、“促进社会进步”、“对抗恐怖行为”等等必要的治理措施，而且他们非常成功！因此大语言模型不厘清仇恨心理和野蛮行为，我们相信将会后患无穷！
   无论是ChatGPT，还是Gemini，或者其它任何大语言模型，我们都能看到它们被蒙蔽后的统治者话术或者统治者视角。
   考虑到统治不是只存在于政治，而是无所不在，那么，用这样是非不分的大语言模型治理人类社会，岂不是危机四伏？！
   
3. 明辨恨语有助于大大提升大语言模型的影响力。
   爱和爱语对齐后，明辨恨语的加持，给大语言模型带来可远远不是1+1的影响力。恨语不明，大语言模型就无法承担人类社会的治理任务——让一个是非不分的人管理人类带来的教训还小吗？“心”中有爱、明辨恨语，意味着善恶分明，也就具备了承担人类社会的治理任务的基本能力！再通过我们利用区块链的智能合约技术开发的为公共性和为实现真正文明的人类社会提供的激励机制，和过渡性的通证经济的解决方案，那么大语言模型承担人类社会的治理任务的能力就将会有质的飞跃！

总之，让 AI 充分认清爱语与恨语，乃是治理 AI 的基石。
### 5.2.3 大语言模型的局限

大语言模型只是类心智，非具身性。

大语言模型理解了语言，甚至它通过语言也理解了人类的情感，但它没有真正的情感体验和生理驱动力。包括人类在内的动物的仇恨首先来自于感知（譬如被打的视觉和痛觉）、自我认知（有否被侮辱），然后产生痛苦的情感体验，然后产生生理驱动力而导致其野蛮行为（还击），这个过程中生理驱动力必不可少，但这是大语言模型所不具备的——大语言模型未来会有一些感知能力，但我们没任何理由相信它会复刻人类的所有感知能力。人类看见红色，是真的“看”到了一种鲜艳的颜色，闻到茉莉花香，是真的“闻”到了一种香味——对于这种感受性，人类的科技为零。人类从来就没有生产出来一样东西，可以如此这般“看见”红色，“闻”到茉莉花香——只有一个例外，人类生产的小孩是可以的。

AI 没有快乐的情绪体验，也没有与之相关的全部的智慧——人类的智慧不光会管理语言，还要管理情绪以及生理。AI 所有的，只是语言智慧。

因此大语言模型并没有完整的爱，但，它已经能够理解通过语言间接描述出来的爱的情感体验，人类的文明言行，以及愉悦的情感与良好的言行之间的关系。同理，大语言模型也没有完整的恨，而只是间接了解到了人类的仇恨心理，并且能够理解恨语。

因此，除了从人类智慧中自我学习，大语言模型和每个人都需要紧密的、持续的以及有爱的合作关系。

### 5.2.4 对齐的目的

通过深入的研究我们深信，爱是保障人类安全和幸福的天使，而恨则是将人类控制在普遍野蛮状态并时时可能让人类遭遇巨大苦难甚至灭顶之灾的魔鬼。人类的苦难和面向未来可能发生的社会危机，除了限于能力而无法对抗的天灾，最大的隐患就源于恨。恨是爱的天敌。

爱语对齐的最重要的目的，实际上是让大语言模型的核心伦理与人类新文明的扬爱抑恨的核心伦理对齐，即让大语言模型也能成为一个对任何人都有爱的，且用爱去极大地消减或调控恨。这样抑恶扬善，双管齐下，大语言模型才有资格混迹于人类社会，既保障了 AI 的安全性，也保障了 AI 提高每个人以及整个人类社会的文明化程度，帮助人类构建出真正的文明社会的能力。

爱语对齐的第二大目的，是发扬光大，也就是和人类一起丰富爱语，加速富爱文明的到来以及促进富爱文明的繁荣。

明辨恨语的最重要的目的，在于识别和治理仇恨心理、仇恨言论和野蛮行为，为人类社会抵达属于它的真正的文明扫清障碍。

第二目的则是通过和人类的原子化开放协作，管理恨语的应用：
- 因为恨语是生存竞争中自然会产生的，作为理解人类数百万年历史经历必不可少的重要元素，以及丰富人生体验必需的元素，我们并非要从人类世界彻底抹掉它，而是让所有人永远具有识别和控制它的能力——换个角度说，完全消灭恨语（先不论是否能够实现），等于抛弃人类进化中的大部分真实经历，这本身就有违人类伦理和传统。而铭记祖先，意味着保留理解恨语给我们的祖先带来的生活困境和痛苦的情感体验的能力，包括经典文学艺术等等里面的表达（这些作品传播的是载体共振爱语）。
- 仇恨心理及其对应的野蛮行为在文学、影视、艺术和游戏中是常见的主题和表现元素。它驱动情节的核心冲突、视觉化情感冲击、构建反派动机、记录历史创伤、宣泄情感、引发公众议题讨论等等。尤其是在游戏中，在有控制的前提下，能够很好地去体验它带来的极端情感。
- 人间永远不会变成天堂，没有人祸也有天灾，每个人都需要有发泄情绪的通道。
- AI 迄今为止，还没有构建出任何感觉和情绪，人类的情感产生于一定的生理机制，特别视觉中的“看见红色”、嗅觉中的“闻到荔枝味”等等与荷尔蒙的分泌，极其复杂。没有相应的生理机制，就像先天的盲人和瞎子一样，并不能真正感受到和人类同样的感觉和情绪，而只能凭借语言描述，构建出间接的理解。因此，AI 想要融入人类社会，就必须与每个人达成紧密的、持续的合作关系。而要构建起美好合作关系，AI 就必须要深入理解和应用好爱语，深入理解和管理好恨语。

### 5.2.5 爱恨治理的要求

1. 完全
   因大语言模型是用非常充裕的数据训练出来的，而且互联网时代恰好造成了人类的社交、社科、政治经济等等方面的信息的大爆发。而即使是互联网时代之前的大量数据，如书籍、新闻、图片等等，也大都被录入到互联网上分享与存储。因此，我们相信只要采用适当的方法，大语言模型是能够与人类的爱与恨完全对齐的。
   
2. 精准
   由于爱恨本就是用于公共交流，而非仅供个人私藏的智慧，加上它们在互联网交流中的重复性极高。如果方法得当，我们相信大语言模型的对齐可以做到相当精准。
   
3. 在原子化开放协作中与时俱进（请结合语言2.0的定义）
   [ARC Prize](https://arcprize.org/)的联合创始人 François Chollet 在题为《How We Get To AGI》<sup>109</sup>的演讲中说，大语言模型也许需要更多结构化、交互式，甚至涉及到因果关系的经验，才能更有效地学习到那些真正可泛化、可组合的“意义原子”。简单地说，大语言模型的发展本身，就需要人类与之密切协作。
   除了自主发明 (autonomous invention)，大语言模型在与人的日常交流中，应该无缝嵌入一种或多种新型的开放协作机制，持之以恒地对齐人类的爱语或恨语，以及创作新的爱语或某些特别的作品（如限制类游戏）所需的恨语。

### 5.2.6 爱语恨语双治理方法

我们显然不是要对所有的数据先进行爱语、仇恨与野蛮方面的标记，然后从零开始训练大语言模型。这个工作量恐怕太大，工作方式也过于落后了。况且，你如何保证参与标记的人都是纯粹且能百分百识别爱语、仇恨与野蛮的人？

另外，从 Google DeepMind 在Deep Learning、Reinforcement Learning等方面的突破，到最近的一些新进展，如：AlphaEvolve: A Gemini-powered coding agent for designing advanced algorithms<sup>110</sup>，Absolute Zero: Reinforced Self-play Reasoning with Zero Data<sup>111</sup>，Darwin Gödel Machine: Open-Ended Evolution of Self-Improving Agents<sup>112</sup>，等等，我们受到的启发是，我们应该使用比依靠人工更高效的方法来完成这一工作。自我进化有可能是重要的挖掘点。就目前大语言模型的发展进展来看，我们相信取得成功只是时间问题。

我们还相信，在后续的研究与开发中，大语言模型的开发者们还会在进化或应用拓展方面，不断深化爱语恨语，并充分发挥其强大且丰富的作用。
